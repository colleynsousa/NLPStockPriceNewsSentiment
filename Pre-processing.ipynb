{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e38b335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e11a117",
   "metadata": {},
   "source": [
    "Feature Engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757dd02",
   "metadata": {},
   "source": [
    "Truth is, this dataset is relatively small. Thus we try to create numerical features from NLP which may be simpler, interpretable, and data-efficient. We may be missing out on some subtleties, but training deep NLP on limited data is likely to overfit. We start with simple feature additions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5c0da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('headlinesNLPdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c732099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Headlines</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>return</th>\n",
       "      <th>direction</th>\n",
       "      <th>headline_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13956</td>\n",
       "      <td>Virgin Galactic and Upwork among industrial g...</td>\n",
       "      <td>DSS</td>\n",
       "      <td>2020-07-09 01:01:00</td>\n",
       "      <td>-0.088750</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13955</td>\n",
       "      <td>DNJR leads financial gainers, BYFC and BSBK a...</td>\n",
       "      <td>BTBT</td>\n",
       "      <td>2020-07-09 01:07:00</td>\n",
       "      <td>-0.243243</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13951</td>\n",
       "      <td>Comscore renews agreement for ondemand essent...</td>\n",
       "      <td>SCOR</td>\n",
       "      <td>2020-07-09 01:20:00</td>\n",
       "      <td>0.066434</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13950</td>\n",
       "      <td>Notable earnings before Friday's open</td>\n",
       "      <td>GBX</td>\n",
       "      <td>2020-07-09 01:21:00</td>\n",
       "      <td>0.155157</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13949</td>\n",
       "      <td>Aramark's self-guided convenience store recei...</td>\n",
       "      <td>ARMK</td>\n",
       "      <td>2020-07-09 01:21:00</td>\n",
       "      <td>0.040924</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          Headlines ticker  \\\n",
       "0       13956   Virgin Galactic and Upwork among industrial g...    DSS   \n",
       "1       13955   DNJR leads financial gainers, BYFC and BSBK a...   BTBT   \n",
       "2       13951   Comscore renews agreement for ondemand essent...   SCOR   \n",
       "3       13950             Notable earnings before Friday's open     GBX   \n",
       "4       13949   Aramark's self-guided convenience store recei...   ARMK   \n",
       "\n",
       "                  date    return  direction  headline_length  word_count  \n",
       "0  2020-07-09 01:01:00 -0.088750          0               78          11  \n",
       "1  2020-07-09 01:07:00 -0.243243          0               58           9  \n",
       "2  2020-07-09 01:20:00  0.066434          1               65           8  \n",
       "3  2020-07-09 01:21:00  0.155157          1               39           5  \n",
       "4  2020-07-09 01:21:00  0.040924          1               78           9  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding headline length & word count\n",
    "data['headline_length']=data['Headlines'].apply(len)\n",
    "data['word_count']=data['Headlines'].apply(lambda x: len(x.split()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3f321",
   "metadata": {},
   "source": [
    "Adding more features here: headline length and word count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30c9fc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Headlines</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>return</th>\n",
       "      <th>direction</th>\n",
       "      <th>headline_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13956</td>\n",
       "      <td>Virgin Galactic and Upwork among industrial g...</td>\n",
       "      <td>DSS</td>\n",
       "      <td>2020-07-09 01:01:00</td>\n",
       "      <td>-0.088750</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13955</td>\n",
       "      <td>DNJR leads financial gainers, BYFC and BSBK a...</td>\n",
       "      <td>BTBT</td>\n",
       "      <td>2020-07-09 01:07:00</td>\n",
       "      <td>-0.243243</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13951</td>\n",
       "      <td>Comscore renews agreement for ondemand essent...</td>\n",
       "      <td>SCOR</td>\n",
       "      <td>2020-07-09 01:20:00</td>\n",
       "      <td>0.066434</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13950</td>\n",
       "      <td>Notable earnings before Friday's open</td>\n",
       "      <td>GBX</td>\n",
       "      <td>2020-07-09 01:21:00</td>\n",
       "      <td>0.155157</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13949</td>\n",
       "      <td>Aramark's self-guided convenience store recei...</td>\n",
       "      <td>ARMK</td>\n",
       "      <td>2020-07-09 01:21:00</td>\n",
       "      <td>0.040924</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          Headlines ticker  \\\n",
       "0       13956   Virgin Galactic and Upwork among industrial g...    DSS   \n",
       "1       13955   DNJR leads financial gainers, BYFC and BSBK a...   BTBT   \n",
       "2       13951   Comscore renews agreement for ondemand essent...   SCOR   \n",
       "3       13950             Notable earnings before Friday's open     GBX   \n",
       "4       13949   Aramark's self-guided convenience store recei...   ARMK   \n",
       "\n",
       "                 date    return  direction  headline_length  word_count  \\\n",
       "0 2020-07-09 01:01:00 -0.088750          0               78          11   \n",
       "1 2020-07-09 01:07:00 -0.243243          0               58           9   \n",
       "2 2020-07-09 01:20:00  0.066434          1               65           8   \n",
       "3 2020-07-09 01:21:00  0.155157          1               39           5   \n",
       "4 2020-07-09 01:21:00  0.040924          1               78           9   \n",
       "\n",
       "   day_0  day_1  day_2  day_3  day_4  day_5  day_6  \n",
       "0      0      0      0      1      0      0      0  \n",
       "1      0      0      0      1      0      0      0  \n",
       "2      0      0      0      1      0      0      0  \n",
       "3      0      0      0      1      0      0      0  \n",
       "4      0      0      0      1      0      0      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding date based features\n",
    "data['date']=pd.to_datetime(data['date'],errors='coerce')\n",
    "data['day_of_week']=data['date'].dt.dayofweek #Monday=0, Sunday=6\n",
    "day_dummies=pd.get_dummies(data['day_of_week'],prefix='day').astype(int) #need to convert to dummy variables for sake of NLP\n",
    "data=pd.concat([data,day_dummies],axis=1)\n",
    "data=data.drop('day_of_week',axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf67cb3",
   "metadata": {},
   "source": [
    "Again, adding another feature: day of the week, which may impact the movement of the stock. We'll note the conversion to dummy variables, considering that Monday = 0 and Sunday = 6 carries no meaning numerically (True/False -> 1/0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c63093e",
   "metadata": {},
   "source": [
    "NLP stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "878eed4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Headlines</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>return</th>\n",
       "      <th>direction</th>\n",
       "      <th>headline_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>neu_sentiment</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>compound_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13956</td>\n",
       "      <td>Virgin Galactic and Upwork among industrial g...</td>\n",
       "      <td>DSS</td>\n",
       "      <td>2020-07-09 01:01:00</td>\n",
       "      <td>-0.088750</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13955</td>\n",
       "      <td>DNJR leads financial gainers, BYFC and BSBK a...</td>\n",
       "      <td>BTBT</td>\n",
       "      <td>2020-07-09 01:07:00</td>\n",
       "      <td>-0.243243</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13951</td>\n",
       "      <td>Comscore renews agreement for ondemand essent...</td>\n",
       "      <td>SCOR</td>\n",
       "      <td>2020-07-09 01:20:00</td>\n",
       "      <td>0.066434</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13950</td>\n",
       "      <td>Notable earnings before Friday's open</td>\n",
       "      <td>GBX</td>\n",
       "      <td>2020-07-09 01:21:00</td>\n",
       "      <td>0.155157</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13949</td>\n",
       "      <td>Aramark's self-guided convenience store recei...</td>\n",
       "      <td>ARMK</td>\n",
       "      <td>2020-07-09 01:21:00</td>\n",
       "      <td>0.040924</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.5574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          Headlines ticker  \\\n",
       "0       13956   Virgin Galactic and Upwork among industrial g...    DSS   \n",
       "1       13955   DNJR leads financial gainers, BYFC and BSBK a...   BTBT   \n",
       "2       13951   Comscore renews agreement for ondemand essent...   SCOR   \n",
       "3       13950             Notable earnings before Friday's open     GBX   \n",
       "4       13949   Aramark's self-guided convenience store recei...   ARMK   \n",
       "\n",
       "                 date    return  direction  headline_length  word_count  \\\n",
       "0 2020-07-09 01:01:00 -0.088750          0               78          11   \n",
       "1 2020-07-09 01:07:00 -0.243243          0               58           9   \n",
       "2 2020-07-09 01:20:00  0.066434          1               65           8   \n",
       "3 2020-07-09 01:21:00  0.155157          1               39           5   \n",
       "4 2020-07-09 01:21:00  0.040924          1               78           9   \n",
       "\n",
       "   day_0  day_1  day_2  day_3  day_4  day_5  day_6  neg_sentiment  \\\n",
       "0      0      0      0      1      0      0      0          0.254   \n",
       "1      0      0      0      1      0      0      0          0.298   \n",
       "2      0      0      0      1      0      0      0          0.000   \n",
       "3      0      0      0      1      0      0      0          0.000   \n",
       "4      0      0      0      1      0      0      0          0.000   \n",
       "\n",
       "   neu_sentiment  pos_sentiment  compound_sentiment  \n",
       "0          0.746          0.000             -0.5267  \n",
       "1          0.702          0.000             -0.5267  \n",
       "2          0.686          0.314              0.4939  \n",
       "3          1.000          0.000              0.0000  \n",
       "4          0.690          0.310              0.5574  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer=SentimentIntensityAnalyzer()\n",
    "data[['neg_sentiment', 'neu_sentiment', 'pos_sentiment', 'compound_sentiment']] = data['Headlines'].apply(lambda x: pd.Series(analyzer.polarity_scores(x)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14daf90d",
   "metadata": {},
   "source": [
    "The 'compound sentiment' here from VADER summarizes the overall sentiment (positive sentiment is positive numerically, negative sentiment is negative numerically, 0 is neutral). We also include the negative, neutral, and positive sentiment scores for additional features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2740c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "/Users/enzo/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Headlines</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>return</th>\n",
       "      <th>direction</th>\n",
       "      <th>headline_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>...</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>neu_sentiment</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>finbert_neg</th>\n",
       "      <th>finbert_neu</th>\n",
       "      <th>finbert_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13956</td>\n",
       "      <td>Virgin Galactic and Upwork among industrial g...</td>\n",
       "      <td>DSS</td>\n",
       "      <td>2020-07-09 01:01:00</td>\n",
       "      <td>-0.088750</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5267</td>\n",
       "      <td>9.989373e-01</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>4.511559e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13955</td>\n",
       "      <td>DNJR leads financial gainers, BYFC and BSBK a...</td>\n",
       "      <td>BTBT</td>\n",
       "      <td>2020-07-09 01:07:00</td>\n",
       "      <td>-0.243243</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5267</td>\n",
       "      <td>9.992293e-01</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>6.671073e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13951</td>\n",
       "      <td>Comscore renews agreement for ondemand essent...</td>\n",
       "      <td>SCOR</td>\n",
       "      <td>2020-07-09 01:20:00</td>\n",
       "      <td>0.066434</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>9.998584e-01</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>2.139914e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13950</td>\n",
       "      <td>Notable earnings before Friday's open</td>\n",
       "      <td>GBX</td>\n",
       "      <td>2020-07-09 01:21:00</td>\n",
       "      <td>0.155157</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.999824e-01</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.326873e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13949</td>\n",
       "      <td>Aramark's self-guided convenience store recei...</td>\n",
       "      <td>ARMK</td>\n",
       "      <td>2020-07-09 01:21:00</td>\n",
       "      <td>0.040924</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>2.842021e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.325699e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          Headlines ticker  \\\n",
       "0       13956   Virgin Galactic and Upwork among industrial g...    DSS   \n",
       "1       13955   DNJR leads financial gainers, BYFC and BSBK a...   BTBT   \n",
       "2       13951   Comscore renews agreement for ondemand essent...   SCOR   \n",
       "3       13950             Notable earnings before Friday's open     GBX   \n",
       "4       13949   Aramark's self-guided convenience store recei...   ARMK   \n",
       "\n",
       "                 date    return  direction  headline_length  word_count  \\\n",
       "0 2020-07-09 01:01:00 -0.088750          0               78          11   \n",
       "1 2020-07-09 01:07:00 -0.243243          0               58           9   \n",
       "2 2020-07-09 01:20:00  0.066434          1               65           8   \n",
       "3 2020-07-09 01:21:00  0.155157          1               39           5   \n",
       "4 2020-07-09 01:21:00  0.040924          1               78           9   \n",
       "\n",
       "   day_0  day_1  ...  day_4  day_5  day_6  neg_sentiment  neu_sentiment  \\\n",
       "0      0      0  ...      0      0      0          0.254          0.746   \n",
       "1      0      0  ...      0      0      0          0.298          0.702   \n",
       "2      0      0  ...      0      0      0          0.000          0.686   \n",
       "3      0      0  ...      0      0      0          0.000          1.000   \n",
       "4      0      0  ...      0      0      0          0.000          0.690   \n",
       "\n",
       "   pos_sentiment  compound_sentiment   finbert_neg  finbert_neu   finbert_pos  \n",
       "0          0.000             -0.5267  9.989373e-01     0.000611  4.511559e-04  \n",
       "1          0.000             -0.5267  9.992293e-01     0.000104  6.671073e-04  \n",
       "2          0.314              0.4939  9.998584e-01     0.000120  2.139914e-05  \n",
       "3          0.000              0.0000  9.999824e-01     0.000004  1.326873e-05  \n",
       "4          0.310              0.5574  2.842021e-08     1.000000  9.325699e-09  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now doing the same thing but with \"FinBERT\", which is more financially geared sentiment scorer for text\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\") #loading FinBERT model and tokenizer\n",
    "model=AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "finbert_pipeline=pipeline(\"sentiment-analysis\",model=model,tokenizer=tokenizer,return_all_scores=True) #pipeline for sentiment analysis\n",
    "#function to get FinBERT probabilities for one headline\n",
    "def finbert_probs(text): \n",
    "    result=finbert_pipeline(text)[0]\n",
    "    scores={f\"finbert_{r['label'].lower()}\": r['score'] for r in result}\n",
    "    return pd.Series(scores)\n",
    "\n",
    "data[['finbert_neg','finbert_neu','finbert_pos']]=data['Headlines'].apply(finbert_probs) #apply to all data\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f133fa",
   "metadata": {},
   "source": [
    "Similar to VADER step, but VADER is much more general purpose whereas FinBERT is more geared towards finance. It produces three numeric features here (per headline) that capture the full sentiment distribution (positive, neutral, or negative with the total of the scores summing to 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "665ca050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>beats</th>\n",
       "      <th>revenue</th>\n",
       "      <th>eps</th>\n",
       "      <th>q2</th>\n",
       "      <th>dividend</th>\n",
       "      <th>misses</th>\n",
       "      <th>declares</th>\n",
       "      <th>results</th>\n",
       "      <th>reports</th>\n",
       "      <th>new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virgin Galactic and Upwork among industrial g...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DNJR leads financial gainers, BYFC and BSBK a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comscore renews agreement for ondemand essent...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Notable earnings before Friday's open</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aramark's self-guided convenience store recei...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Keurig Dr Pepper tapped to pour out a beat-an...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMC Networks +5% on reported sale evaluation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Intact Financial announces catastrophe Q2 los...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Assurant declares $0.63 dividend</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NICE upgraded to Buy on pandemic tailwinds</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Headlines  beats  revenue  eps  \\\n",
       "0   Virgin Galactic and Upwork among industrial g...    0.0      0.0  0.0   \n",
       "1   DNJR leads financial gainers, BYFC and BSBK a...    0.0      0.0  0.0   \n",
       "2   Comscore renews agreement for ondemand essent...    0.0      0.0  0.0   \n",
       "3             Notable earnings before Friday's open     0.0      0.0  0.0   \n",
       "4   Aramark's self-guided convenience store recei...    0.0      0.0  0.0   \n",
       "5   Keurig Dr Pepper tapped to pour out a beat-an...    0.0      0.0  0.0   \n",
       "6      AMC Networks +5% on reported sale evaluation     0.0      0.0  0.0   \n",
       "7   Intact Financial announces catastrophe Q2 los...    0.0      0.0  0.0   \n",
       "8                  Assurant declares $0.63 dividend     0.0      0.0  0.0   \n",
       "9        NICE upgraded to Buy on pandemic tailwinds     0.0      0.0  0.0   \n",
       "\n",
       "         q2  dividend  misses  declares  results  reports  new  \n",
       "0  0.000000  0.000000     0.0  0.000000      0.0      0.0  0.0  \n",
       "1  0.000000  0.000000     0.0  0.000000      0.0      0.0  0.0  \n",
       "2  0.000000  0.000000     0.0  0.000000      0.0      0.0  0.0  \n",
       "3  0.000000  0.000000     0.0  0.000000      0.0      0.0  0.0  \n",
       "4  0.000000  0.000000     0.0  0.000000      0.0      0.0  0.0  \n",
       "5  0.000000  0.000000     0.0  0.000000      0.0      0.0  0.0  \n",
       "6  0.000000  0.000000     0.0  0.000000      0.0      0.0  0.0  \n",
       "7  0.329633  0.000000     0.0  0.000000      0.0      0.0  0.0  \n",
       "8  0.000000  0.686487     0.0  0.727142      0.0      0.0  0.0  \n",
       "9  0.000000  0.000000     0.0  0.000000      0.0      0.0  0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now doing some TFIDF stuff - extracting numerical features from headline text by converting important words into TFIDF scores\n",
    "tfidf=TfidfVectorizer(max_features=100,stop_words='english') #limiting to the top 100 words, and not including stop words which might dominate in terms of frequency\n",
    "X_tfidf=tfidf.fit_transform(data['Headlines']) #convert each headline into a vector of TFIDF scores corresponding to top 100 words\n",
    "tfidf_df=pd.DataFrame(X_tfidf.toarray(),columns=tfidf.get_feature_names_out(),index=data.index)\n",
    "data=pd.concat([data,tfidf_df],axis=1)\n",
    "\n",
    "#display these new columns, putting most important words at the front\n",
    "tfidf_cols=tfidf_df.columns\n",
    "avg_tfidf=tfidf_df[tfidf_cols].mean().sort_values(ascending=False)\n",
    "top_words=avg_tfidf.index.tolist()\n",
    "display_cols=['Headlines'] + top_words[:10]\n",
    "data[display_cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c307d181",
   "metadata": {},
   "source": [
    "Now we have 100 new columns with TF-IDF word scores for each headline. As expected, lots of 0s across the board, but this is completely normal considering that are our dataset has lots of different words. Reminder that TF-IDF = Term frequency (how often word appears normalized by length) x Inverse Document frequency (how \"rare\" a word is). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2483b174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Headlines', 'ticker', 'date', 'return', 'direction',\n",
      "       'headline_length', 'word_count', 'day_0', 'day_1',\n",
      "       ...\n",
      "       'strong', 'study', 'systems', 'target', 'tech', 'technologies',\n",
      "       'therapeutics', 'trust', 'vaccine', 'year'],\n",
      "      dtype='object', length=122)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return</th>\n",
       "      <th>direction</th>\n",
       "      <th>headline_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>...</th>\n",
       "      <th>strong</th>\n",
       "      <th>study</th>\n",
       "      <th>systems</th>\n",
       "      <th>target</th>\n",
       "      <th>tech</th>\n",
       "      <th>technologies</th>\n",
       "      <th>therapeutics</th>\n",
       "      <th>trust</th>\n",
       "      <th>vaccine</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.088750</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.243243</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066434</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.155157</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040924</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     return  direction  headline_length  word_count  day_0  day_1  day_2  \\\n",
       "0 -0.088750          0               78          11      0      0      0   \n",
       "1 -0.243243          0               58           9      0      0      0   \n",
       "2  0.066434          1               65           8      0      0      0   \n",
       "3  0.155157          1               39           5      0      0      0   \n",
       "4  0.040924          1               78           9      0      0      0   \n",
       "\n",
       "   day_3  day_4  day_5  ...  strong  study  systems  target  tech  \\\n",
       "0      1      0      0  ...     0.0    0.0      0.0     0.0   0.0   \n",
       "1      1      0      0  ...     0.0    0.0      0.0     0.0   0.0   \n",
       "2      1      0      0  ...     0.0    0.0      0.0     0.0   0.0   \n",
       "3      1      0      0  ...     0.0    0.0      0.0     0.0   0.0   \n",
       "4      1      0      0  ...     0.0    0.0      0.0     0.0   0.0   \n",
       "\n",
       "   technologies  therapeutics  trust  vaccine  year  \n",
       "0           0.0           0.0    0.0      0.0   0.0  \n",
       "1           0.0           0.0    0.0      0.0   0.0  \n",
       "2           0.0           0.0    0.0      0.0   0.0  \n",
       "3           0.0           0.0    0.0      0.0   0.0  \n",
       "4           0.0           0.0    0.0      0.0   0.0  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Minor cleaning\n",
    "print(data.columns)\n",
    "data=data.drop(labels=['Unnamed: 0','Headlines', 'ticker','date'], axis='columns')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c506ac",
   "metadata": {},
   "source": [
    "Checking if we have any remaining categorical data features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05d06259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return             float64\n",
      "direction            int64\n",
      "headline_length      int64\n",
      "word_count           int64\n",
      "day_0                int64\n",
      "                    ...   \n",
      "technologies       float64\n",
      "therapeutics       float64\n",
      "trust              float64\n",
      "vaccine            float64\n",
      "year               float64\n",
      "Length: 118, dtype: object\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "#Checking if we have categorical data\n",
    "print(data.dtypes)\n",
    "print(data.select_dtypes(include=['object','category']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4102a734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "data.to_csv('headlinesNLPdata.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nameOfEnv",
   "language": "python",
   "name": "nameofenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
